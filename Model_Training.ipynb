{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOt12g73S7No0FiaybhVgJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenBryceLee/DengAI/blob/master/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcQl3aqr1tM2",
        "colab_type": "text"
      },
      "source": [
        "The goal of this notebook is to get much farther in model searching without human input, specifically by finding good models, then optimizing their hyperparameters and performing multiple hyperparameter searches, without needing to manually search</br>\n",
        "Difficulties will be that hyperparameters have different ranges and potential values, so this will only work so long as the hyperparameter can be found without reading the documentation. For example, some hyperparameters such as loss function are any of the list ['mse','mae'] which cannot be learned except by reading the documentation. I expect this to be more successful when looking over numeric ranges </br>\n",
        "Competition URL:</br>\n",
        "https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/82/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzErYoTy2Tfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -O features_train.csv 'https://drivendata-prod.s3.amazonaws.com/data/44/public/dengue_features_train.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200817%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200817T143418Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2b3964d4e4cb929566aa344aaf2e07992c25b0daca4ce719cf6c49a3de2ac256'\n",
        "# !wget -O labels_train.csv 'https://drivendata-prod.s3.amazonaws.com/data/44/public/dengue_labels_train.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200817%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200817T143418Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=998c2ef0db8e655154a200e8829ba20682071d35d222224aab6191eed6898366'\n",
        "# !wget -O features_test.csv 'https://drivendata-prod.s3.amazonaws.com/data/44/public/dengue_features_test.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200817%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200817T143418Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=675b5b3940af4e0a439323481472746f28b34e6e901a4a124c9e53fb09e52c12'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGwpvKlM7NyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7f7291d-c550-4957-c9ed-1c9d4a4fe291"
      },
      "source": [
        "try:\n",
        "  import category_encoders\n",
        "except:\n",
        "  !pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmLYcC103btr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0syiK9l4L0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TISqVrjPyjo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFeatures = pd.read_csv('features_train.csv')\n",
        "#trainFeatures.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqBXj5P1zuzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLabels = pd.read_csv('labels_train.csv')\n",
        "#trainLabels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFzRWyQL5CW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.merge(trainFeatures,trainLabels,on=trainLabels.columns[:-1].tolist())\n",
        "#train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGcgZsh3ZuTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('features_test.csv')\n",
        "#test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYMgYIGdU1yC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(df):\n",
        "  '''\n",
        "  This function wrangles training and testing data from the DengAI datasets\n",
        "\n",
        "  df is a pandas df with either train or test data \n",
        "\n",
        "  returns a cleaned df\n",
        "  '''\n",
        "  #Drop empty rows\n",
        "  #df.drop(df[df.weekofyear==53].index,inplace=True)\n",
        "\n",
        "  #convert datetime\n",
        "  df.week_start_date = pd.to_datetime(df.week_start_date)\n",
        "  #Get days, months, years\n",
        "  df['years'] = df.week_start_date.apply(lambda x: x.year)\n",
        "  df['months'] = df.week_start_date.apply(lambda x: x.month)\n",
        "  df['days'] = df.week_start_date.apply(lambda x: x.day)\n",
        "\n",
        "  #Drop datetime object type\n",
        "  df.drop(['week_start_date',\n",
        "           #'weekofyear'\n",
        "           ],axis=1, inplace = True)\n",
        "\n",
        "  # #Only applying to the training dataset, which contains labels\n",
        "  if 'total_cases' in df.columns:\n",
        "    df.dropna(axis=0,thresh=len(df.columns)-8,inplace=True)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9mzgEcI76-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_save(df, y_pred,name):\n",
        "  temp = df[['city','year','weekofyear']].copy()\n",
        "  temp['total_cases'] = y_pred\n",
        "  print(temp.head())\n",
        "  if '.csv' not in name:\n",
        "    name += '.csv'\n",
        "  temp.to_csv(name,index=False)\n",
        "  from google.colab import files\n",
        "  files.download(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZtW_FHWZjw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = wrangle(train)\n",
        "test = wrangle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLIV4kge5niG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pandas-profiling==2.*;\n",
        "# from pandas_profiling import ProfileReport\n",
        "# profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "# profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIuyow7Gf5io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer \n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from category_encoders import OneHotEncoder\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#Non-performant models\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import VotingRegressor \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sWFP15CnE5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.drop('total_cases',axis=1)\n",
        "y = train.total_cases\n",
        "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.25,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHVznGgEl0g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48c74593-173d-4832-ac7a-6630017e60ae"
      },
      "source": [
        "#Get baseline accuracy\n",
        "base = MAE(train['total_cases'],[train['total_cases'].median()] * len(train))\n",
        "base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.863070539419088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7q_aM4Dbz_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Experiment params\n",
        "# params = {'model__loss':['ls','lad','huber'],\n",
        "#           'model__learning_rate':np.linspace(0.0001,0.2,3),\n",
        "#           'model__n_estimators':np.linspace(50,150,3,dtype='int64'),\n",
        "#           'model__criterion': ['friedman_mse','mae'],\n",
        "#           'model__min_samples_split': np.linspace(2,10,3,dtype='int64'),\n",
        "#           'model__min_samples_leaf':np.linspace(1,int(len(X_train) * (1/10)),3,dtype='int64').tolist(),\n",
        "#           'model__max_depth':np.linspace(3,15,3,dtype='int64').tolist(),\n",
        "#           'model__min_impurity_decrease':np.linspace(0,0.9,3),\n",
        "#           'model__init':[None, RandomForestRegressor(random_state=41)] ,\n",
        "#           'model__ccp_alpha':np.linspace(0,0.9,3).tolist(),\n",
        "#           }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rHWZ5mXuwtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prevscore = base\n",
        "# encoders = [#OrdinalEncoder(),\n",
        "#             OneHotEncoder()]\n",
        "# base_estimator = RandomForestRegressor(random_state=41)\n",
        "# est_list = [('rf1',RandomForestRegressor(random_state=1)),\n",
        "#             ('rf2',RandomForestRegressor(random_state=42)),\n",
        "#             ('rf3',RandomForestRegressor(random_state=93))]\n",
        "# models = [\n",
        "#           AdaBoostRegressor(base_estimator,random_state=41), \n",
        "#           GradientBoostingRegressor(random_state=41), \n",
        "#           VotingRegressor(est_list,n_jobs=-1),\n",
        "#           XGBRegressor(random_state=41),\n",
        "#           ]\n",
        "# imputers = [SimpleImputer()\n",
        "#             #,IterativeImputer()\n",
        "#             ]\n",
        "# scalers = [#StandardScaler(),\n",
        "#            MinMaxScaler()]\n",
        "# #Search for the baseline optimum model using \n",
        "# for model in models:\n",
        "#   pipe = Pipeline([\n",
        "#               ('encode',OneHotEncoder()),\n",
        "#               ('impute', SimpleImputer()),\n",
        "#               ('scale',MinMaxScaler()),\n",
        "#               ('model',model)\n",
        "#               ])\n",
        "# #grid = GridSearchCV(pipe,param_grid =params,n_jobs=-1,cv = 3)\n",
        "#   #For each model, fit and predict to get the MAE\n",
        "#   pipe.fit(X_train,y_train)\n",
        "#   y_pred = pipe.predict(X_val)\n",
        "#   # grid.fit(X_train,y_train)\n",
        "#   # y_pred = grid.predict(X_val)\n",
        "#   score = MAE(y_val,y_pred)\n",
        "#   print(score)\n",
        "#   #If the score is a new high score\n",
        "#   if score < prevscore:\n",
        "#     prevscore = score\n",
        "#     # print('encoder:\\t{}\\nimputer:\\t{}\\nscaler:\\t\\t{}\\nmodel:\\t{}\\n'\n",
        "#     #                                                       .format(str(encoder)[:10],\n",
        "#     #                                                       str(imputer)[:10],\n",
        "#     #                                                       str(scaler)[:10],\n",
        "#     #                                                       str(model)[:10]))\n",
        "#     #Store the best model\n",
        "#     modelBest = pipe.named_steps['model']\n",
        "# print(modelBest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlsQ_hKQcxlZ",
        "colab_type": "text"
      },
      "source": [
        "best model </br>\n",
        "12.744609500492475\n",
        "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "             n_jobs=1, nthread=None, objective='reg:linear', random_state=41,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWR439mo6s2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #recreate the pipeline, predict and save\n",
        "# y_pred = modelBest.predict(test)\n",
        "# model_save(test,y_pred,str(score)[:6]+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_o9dk506lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_float = np.linspace(0.1,1,3)\n",
        "params = {'model__model__base_score': [base,0.5],\n",
        "          'model__model__booster': ['gbtree','dart'],\n",
        "          'model__colsample_bylevel': default_float,\n",
        "          'model__colsample_bynode': default_float,\n",
        "          'model__colsample_bytree': default_float,\n",
        "          'model__gamma': np.linspace(0,1,3),\n",
        "          'model__model__importance_type': ['gain','total_gain','cover'],\n",
        "          'model__learning_rate': np.linspace(0.1,0.5,3),\n",
        "          'model__max_delta_step': np.linspace(0,100,3),\n",
        "          'model__model__max_depth': np.linspace(3,100,3,dtype='int64'),\n",
        "          'model__min_child_weight': default_float,\n",
        "          'model__model__n_estimators': np.linspace(75,500,3,dtype='int64'),\n",
        "          'model__model__n_jobs': [-1],\n",
        "          'model__model__nthread': [-1],\n",
        "          'model__objective': ['reg:squarederror'],\n",
        "          'model__model__random_state': np.linspace(75,500,3,dtype='int64'),\n",
        "          'model__reg_alpha': np.linspace(0,1,3),\n",
        "          'model__reg_lambda': np.linspace(0,1,3),\n",
        "          'model__scale_pos_weight': np.linspace(0,1,3),\n",
        "          'model__model__seed': np.linspace(75,500,3,dtype='int64'),\n",
        "          'model__subsample': default_float,\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9PJxL19UbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7463c710-530a-4c73-b345-0b43e5daf0c1"
      },
      "source": [
        "try:\n",
        "  print(grid.get_params().keys())\n",
        "except:\n",
        "  print('no grid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no grid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlmVQJixivjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remake pipeline with the best model\n",
        "pipe = Pipeline([\n",
        "              ('encode',OneHotEncoder()),\n",
        "              ('impute', SimpleImputer()),\n",
        "              ('scale',MinMaxScaler()),\n",
        "              ('model',XGBRegressor())\n",
        "              ])\n",
        "\n",
        "#Initiate random search\n",
        "#grid = RandomizedSearchCV(pipe,param_distributions =params,n_jobs=-1,cv = 5,random_state=91)\n",
        "#Initiate grid search\n",
        "grid = GridSearchCV(pipe,param_grid=params,n_jobs=-1,cv = 5)\n",
        "grid.fit(X_train,y_train)\n",
        "y_pred = grid.predict(X_val)\n",
        "score = MAE(y_val,y_pred)\n",
        "print(score)\n",
        "if score > prevscore:\n",
        "  print('you had a bad idea >:[')\n",
        "else:\n",
        "  y_pred = modelBest.predict(test)\n",
        "  model_save(test,y_pred,str(score)[:6]+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LOsl28bc_v4",
        "colab_type": "text"
      },
      "source": [
        "Raw data grants a MAE of 17.43\n",
        "\n",
        "Baseline MAE with wrangled data is 0.99\n",
        "\n",
        "Model MAE is 0.7. \n",
        "Pipeline:\n",
        "\n",
        "('encode',OneHotEncoder(cols = ['city'],handle_unknown='indicator')),\n",
        "('impute', SimpleImputer()),\n",
        "('scale',StandardScaler()),\n",
        "('model',DecisionTreeRegressor())\n",
        "\n",
        "MAE of 0.48:\n",
        "OneHotEncoder, SimpleImputer, RandomForestReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdaEJ0uqtGV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}